{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习的要义：\n",
    "1. 系统性学习：只言片语的学，只会一叶遮目，只见树木，不见森林。系统性的学习，才能知道事物的始末，你才能知道怎么创造。\n",
    "2. 多实战：学习最好的方式是教给别人，因为讲，需要条理清晰的知道每个细节。实战也是一种另一种形式的“讲”。\n",
    "3. 多复习：人脑存在遗忘机制，遗忘不是不好，遗忘是因为大脑不知道记忆的东西重要还是不重要。当你不停的重复记忆，大脑才能知道这项东西非常重要。\n",
    "本文是 PyTorch 的第一讲，打算写一个完整的系列，用这一系列，从0到1的系统性学习PyTorch。学习完的效果是要能从0到1独立复现任何一篇Paper。\n",
    "言归正传，本文是一个开胃菜，遵循先整体后局部的思路。第一讲，将讲述本文总结的深度学习代码模板。深度学习没有那么高深，所有深度学习模板都遵循着这一模版。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络学习七步法\n",
    "\n",
    "[系统性学习PyTorch之第一讲深度学习的模板](https://zhuanlan.zhihu.com/p/599280748)\n",
    "\n",
    "[pytorch/tutorials/beginner_source/basics/quickstart_tutorial.py](https://github.com/pytorch/tutorials/blob/main/beginner_source/basics/quickstart_tutorial.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guchen/opt/anaconda3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import liberies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1195716f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "seed = 0 \n",
    "np.random.seed(seed=seed)\n",
    "torch.random.manual_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步: 数据集- 使用 Dataset 封装数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 11176967.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 918066.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 8813566.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 14708635.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_data = datasets.FashionMNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步 : 加载数据集：使用 DataLoader 生成一个迭代器，用的时候记得传入 batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  第三步 : 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建NN Class，继承 nn.Module，实现 forward 函数\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Loss Function\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 使用内置的Loss Function\n",
    "\n",
    "\n",
    "# 继承 nn.Module，自定义loss，通常复现论文时使用\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        target = torch.LongTensor(target)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(output, target)\n",
    "        mask = target == 9\n",
    "        high_cost = (loss * mask.float()).mean()\n",
    "        return loss + high_cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步 : 设定训练参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#  实例化NN函数，并 to(device)\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写train 函数\n",
    "# 1. 用train模式：model.train()\n",
    "# 2. loop 数据\n",
    "# 3. predict，并计算 loss\n",
    "# 4. 反向传播\n",
    "# 5. 每N个 batch，打印 loss和 acc\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第五步 : train 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Test Error: Accuracy: 79.2%, Avg loss: 0.605012\n",
      "Epoch 2:\n",
      "Test Error: Accuracy: 79.5%, Avg loss: 0.595239\n",
      "Epoch 3:\n",
      "Test Error: Accuracy: 79.6%, Avg loss: 0.588063\n",
      "Epoch 4:\n",
      "Test Error: Accuracy: 80.0%, Avg loss: 0.579006\n",
      "Epoch 5:\n",
      "Test Error: Accuracy: 80.2%, Avg loss: 0.572682\n",
      "Epoch 6:\n",
      "Test Error: Accuracy: 80.1%, Avg loss: 0.566434\n",
      "Epoch 7:\n",
      "Test Error: Accuracy: 80.3%, Avg loss: 0.562854\n",
      "Epoch 8:\n",
      "Test Error: Accuracy: 80.6%, Avg loss: 0.553573\n",
      "Epoch 9:\n",
      "Test Error: Accuracy: 80.6%, Avg loss: 0.547929\n",
      "Epoch 10:\n",
      "Test Error: Accuracy: 80.9%, Avg loss: 0.544086\n",
      "Epoch 11:\n",
      "Test Error: Accuracy: 80.9%, Avg loss: 0.540304\n",
      "Epoch 12:\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 0.534956\n",
      "Epoch 13:\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 0.532731\n",
      "Epoch 14:\n",
      "Test Error: Accuracy: 81.3%, Avg loss: 0.527043\n",
      "Epoch 15:\n",
      "Test Error: Accuracy: 81.6%, Avg loss: 0.524065\n",
      "Epoch 16:\n",
      "Test Error: Accuracy: 81.7%, Avg loss: 0.521020\n",
      "Epoch 17:\n",
      "Test Error: Accuracy: 81.7%, Avg loss: 0.517351\n",
      "Epoch 18:\n",
      "Test Error: Accuracy: 81.8%, Avg loss: 0.515438\n",
      "Epoch 19:\n",
      "Test Error: Accuracy: 81.9%, Avg loss: 0.512016\n",
      "Epoch 20:\n",
      "Test Error: Accuracy: 81.9%, Avg loss: 0.510355\n",
      "Epoch 21:\n",
      "Test Error: Accuracy: 82.0%, Avg loss: 0.507104\n",
      "Epoch 22:\n",
      "Test Error: Accuracy: 82.1%, Avg loss: 0.503844\n",
      "Epoch 23:\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 0.502293\n",
      "Epoch 24:\n",
      "Test Error: Accuracy: 82.4%, Avg loss: 0.499892\n",
      "Epoch 25:\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 0.498499\n",
      "Epoch 26:\n",
      "Test Error: Accuracy: 82.3%, Avg loss: 0.497180\n",
      "Epoch 27:\n",
      "Test Error: Accuracy: 82.5%, Avg loss: 0.493738\n",
      "Epoch 28:\n",
      "Test Error: Accuracy: 82.5%, Avg loss: 0.492871\n",
      "Epoch 29:\n",
      "Test Error: Accuracy: 82.5%, Avg loss: 0.490252\n",
      "Epoch 30:\n",
      "Test Error: Accuracy: 82.7%, Avg loss: 0.488944\n",
      "Epoch 31:\n",
      "Test Error: Accuracy: 82.7%, Avg loss: 0.490488\n",
      "Epoch 32:\n",
      "Test Error: Accuracy: 82.6%, Avg loss: 0.486189\n",
      "Epoch 33:\n",
      "Test Error: Accuracy: 82.8%, Avg loss: 0.484049\n",
      "Epoch 34:\n",
      "Test Error: Accuracy: 82.9%, Avg loss: 0.482155\n",
      "Epoch 35:\n",
      "Test Error: Accuracy: 82.9%, Avg loss: 0.482324\n",
      "Epoch 36:\n",
      "Test Error: Accuracy: 82.9%, Avg loss: 0.479293\n",
      "Epoch 37:\n",
      "Test Error: Accuracy: 83.0%, Avg loss: 0.478675\n",
      "Epoch 38:\n",
      "Test Error: Accuracy: 83.0%, Avg loss: 0.477791\n",
      "Epoch 39:\n",
      "Test Error: Accuracy: 83.0%, Avg loss: 0.475591\n",
      "Epoch 40:\n",
      "Test Error: Accuracy: 83.2%, Avg loss: 0.474167\n",
      "Epoch 41:\n",
      "Test Error: Accuracy: 83.1%, Avg loss: 0.475961\n",
      "Epoch 42:\n",
      "Test Error: Accuracy: 83.2%, Avg loss: 0.472830\n",
      "Epoch 43:\n",
      "Test Error: Accuracy: 83.2%, Avg loss: 0.471786\n",
      "Epoch 44:\n",
      "Test Error: Accuracy: 83.4%, Avg loss: 0.469563\n",
      "Epoch 45:\n",
      "Test Error: Accuracy: 83.0%, Avg loss: 0.470966\n",
      "Epoch 46:\n",
      "Test Error: Accuracy: 83.5%, Avg loss: 0.466530\n",
      "Epoch 47:\n",
      "Test Error: Accuracy: 83.3%, Avg loss: 0.467221\n",
      "Epoch 48:\n",
      "Test Error: Accuracy: 83.4%, Avg loss: 0.466307\n",
      "Epoch 49:\n",
      "Test Error: Accuracy: 83.4%, Avg loss: 0.465060\n",
      "Epoch 50:\n",
      "Test Error: Accuracy: 83.5%, Avg loss: 0.463356\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}:\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第六步 : save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'data/0_FashionMINST_NN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第七步 : inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"data/0_FashionMINST_NN.pth\"))\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6611e8243679266c8095de3ce3581dc97b2fcbb87aca5381fe182ad20c132290"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
